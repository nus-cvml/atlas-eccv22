<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="main.css" type="text/css" />
<link rel="stylesheet" href="font-awesome/css/font-awesome.min.css">
<!--- <title></title> --->
<title>ATLAS Tutorial ECCV22</title>
<!-- MathJax -->
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML' async>
</script>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
	  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
<!-- End MathJax -->
</head>
<body>
<div id="main-container">
<div id="header-container">
<div id="header">
<div id="header-icon-text-container">
<!--
<div id="header-icon-container" >
<a href="index.html"><img src="./images/icon.png" alt="" style="width: 100%; height: 100%; position: center; padding:0px; margin: 0px;"></a>
</div>
-->
<div id="header-text-container">
<a href="index.html">ATLAS Tutorial</a>
</div>
</div>
<!--
<div id="main">
<button class="openbtn" onclick="openNav()">☰</button>
</div>
-->
</div>
</div>
<div id="layout-content">
<div id="text-img-container"><div id="img-container">
<a href="https://atlas-eccv22.github.io"><img src="./logos/atlas.png" alt="atlas" width="100%" /></a></div>
<div id="text-container"></div></div>
<p>
<div id="beamer">
<beam> 
<b>A</b>c<b>T</b>ion <b>L</b>ocalization <b>A</b>nd <b>S</b>egmentation in Video
</beam></br>
<beams>
in conjunction with ECCV 2022, TEL AVIV</br>
Israel C (120), Dan Panorama, Monday Morning, October 24, 2022 
</beams>
</div>
</p>
<h1>Overview </h1>
<p>The majority of research in action understanding focuses on designing methods to encode a few seconds of short, trimmed clips and classify these with single action labels. 
Such methods, however, are rarely applicable for temporally localizing and/or classifying actions from longer streams of video. 
In this tutorial, we would like to focus on research on understanding actions long videos up to tens of minutes.<br /></p>
<p>Compared to action recognition from trimmed video clips long video understanding tasks pose more challenges due to the long span of videos and complex temporal relations between occurring actions. 
Such challenges include: <i>“What are the actions and when do these actions happen in the long video sequences?”</i> 
Our main focus for this tutorial is two tasks that aim to find human actions in videos, <i>i.e.</i>,  Temporal Action Localization/Detection (TAL/D) and Temporal Action Segmentation (TAS).</p>
<h1>Speakers</h1>
<p>
<div id="member-container">
<div id="member">
<img src="./profiles/angela.png">
<p>
<b><a href="https://www.comp.nus.edu.sg/~ayao/">Angela Yao</a></b></br>
Assistant Professor, National University of Singapore
</p>
</div>
<div id="member">
<img src="./profiles/junsong.png">
<p>
<b><a href="https://cse.buffalo.edu/~jsyuan/">Junsong Yuan</a></b></br>
Professor, SUNY Buffalo
</p>
</div> 
<div id="member">
<img src="./profiles/hilde.png">
<p>
<b><a href="https://hildekuehne.github.io/">Hilde Kuehne</a></b></br>
Assistant Professor, Goethe University
</p>
</div>
<div id="member">
<img src="./profiles/ehsan.png">
<p>
<b><a href="https://www.ccs.neu.edu/home/eelhami/">Ehsan Elhamifar</a></b></br>
Associate Professor, Northeastern University
</p>
</div>
<div id="member">
<img src="./profiles/yougesh.png">
<p>
<b><a href="https://www.crcv.ucf.edu/person/rawat/">Yogesh S Rawat</a></b></br>
Assistant Professor, University of Central Florida
</p>
</div>
</div>
</p>
<h1>Schedule</h1>
<p>For those who are not attending in person, you may join us over Zoom with the following link.</p>
<ul>
<li><p><b>Opening Remarks</b> (9:00 - 9:10am, <i>Organizers</i>) </p>
</li>
<li><p><b>Temporal Action Segmentation</b> (9:10 - 9:45am, <i>Yao</i>) [<a href="video" target=&ldquo;blank&rdquo;>video</a>] [<a href="slide" target=&ldquo;blank&rdquo;>slide</a>]</p>
</li>
<li><p><b>Temporal Action Localization</b> (9:45 - 10:20am, <i>Yuan</i>) [<a href="video" target=&ldquo;blank&rdquo;>video</a>] [<a href="slide" target=&ldquo;blank&rdquo;>slide</a>]</p>
</li>
<li><p><b>Coffee Break</b> (10:20 - 10:40am) </p>
</li>
<li><p><b>Spatio-Temporal Action Localization</b> (10:40 - 11:15am, <i>Kuehne</i>) [<a href="video" target=&ldquo;blank&rdquo;>video</a>] [<a href="slide" target=&ldquo;blank&rdquo;>slide</a>]</p>
</li>
<li><p><b>Multimodal Segmentation</b> (11:15 - 11:50am, <i>Elhamifar</i>) [<a href="video" target=&ldquo;blank&rdquo;>video</a>] [<a href="slide" target=&ldquo;blank&rdquo;>slide</a>]</p>
</li>
<li><p><b>Action Detection</b> (11:50 - 12:25am, <i>Rawat</i>) [<a href="video" target=&ldquo;blank&rdquo;>video</a>] [<a href="slide" target=&ldquo;blank&rdquo;>slide</a>]</p>
</li>
<li><p><b>Conclusion</b> (12:25 - 12:30pm, All)</p>
</li>
</ul>
<h1>Resources</h1>
<ul>
<li><p><b>Work Compliation</b></p>
</li>
</ul>
<ol>
<li><p>Awesome Temporal Action Segmentation [<a href="https://github.com/atlas-eccv22/awesome-temporal-action-segmentation" target=&ldquo;blank&rdquo;>Github</a>]</p>
</li>
<li><p>Awesome Temporal Action Localization [<a href="https://github.com/Alvin-Zeng/Awesome-Temporal-Action-Localization" target=&ldquo;blank&rdquo;>Github</a>]</p>
</li>
</ol>
<ul>
<li><p><b>Survey</b></p>
</li>
</ul>
<ol>
<li><p>Temporal Action Segmentation: An Analysis of Modern Technique, <i>2022</i>. Guodong Ding, Fadime Sener and Angela Yao. [<a href="https://arxiv.org/pdf/2210.10352.pdf" target=&ldquo;blank&rdquo;>PDF</a>]</p>
</li>
<li><p>Weakly-supervised temporal action localization: a survey, <i>2022</i>. AbdulRahman Baraka and Mohd Halim Mohd Noor. [<a href="https://link.springer.com/article/10.1007/s00521-022-07102-x" target=&ldquo;blank&rdquo;>PDF</a>]</p>
</li>
<li><p>A Survey on Temporal Action Localization, <i>2020</i>. Huifen Xia and Yongzhao Zhan [<a href="https://ieeexplore.ieee.org/document/9062498" target=&ldquo;blank&rdquo;>PDF</a>]</p>
</li>
</ol>
<h1>Organizers</h1>
<p>
<div id="member-container">
<div id="member">
<img src="./profiles/angela.png">
<p>
<b>Angela Yao</b></br>
Assistant Professor, National University of Singapore
</p>
</div>
<div id="member">
<img src="./profiles/junsong.png">
<p>
<b>Junsong Yuan</b></br>
Professor, SUNY Buffalo
</p>
</div>
<div id="member">
<img src="./profiles/fadime.png">
<p>
<b>Fadime Sener</b></br>
Research Scientist, Reality Labs, Meta
</p>
</div>
<div id="member">
<img src="./profiles/guodong.png">
<p>
<b>Guodong Ding</b></br>
Research Fellow, National University of Singapore
</p>
</div>
</div>
</p>
<div id="footer">
<div id="footer-text">
Last edited  on October 23<sup>rd</sup> 2022  10:19AM (Time Zone: IDT). </br>
</div>
</div>
</div>
</body>
</html>
