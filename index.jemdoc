
~~~
{}{img_left}{./logos/atlas.png}{atlas}{100%}{}{https://atlas-eccv22.github.io}
~~~

{{
<div id="beamer">
<beam> 
<b>A</b>c<b>T</b>ion <b>L</b>ocalization <b>A</b>nd <b>S</b>egmentation in Video
</beam></br>
<beams>
in conjunction with ECCV 2022, TEL AVIV</br>
Israel C (120), Dan Panorama, Monday Morning, October 24, 2022 
</beams>
</div>
}}

= Overview 
The majority of research in action understanding focuses on designing methods to encode a few seconds of short, trimmed clips and classify these with single action labels. 
Such methods, however, are rarely applicable for temporally localizing and\/or classifying actions from longer streams of video. 
In this tutorial, we would like to focus on research on understanding actions long videos up to tens of minutes.\n
    
Compared to action recognition from trimmed video clips long video understanding tasks pose more challenges due to the long span of videos and complex temporal relations between occurring actions. 
Such challenges include: /“What are the actions and when do these actions happen in the long video sequences?”/ 
Our main focus for this tutorial is two tasks that aim to find human actions in videos, /i.e./,  Temporal Action Detection\/Localization (TAD\/L) and Temporal Action Segmentation (TAS).


= Speakers
{{
<div id="member-container">
    <div id="member">
        <img src="./profiles/angela.png">
        <p>
            <b><a href="https://www.comp.nus.edu.sg/~ayao/">Angela Yao</a></b></br>
            Assistant Professor, National University of Singapore
        </p>
    </div>
    <div id="member">
        <img src="./profiles/junsong.png">
        <p>
            <b><a href="https://cse.buffalo.edu/~jsyuan/">Junsong Yuan</a></b></br>
            Professor, SUNY Buffalo
        </p>
    </div> 
    <div id="member">
        <img src="./profiles/hilde.png">
        <p>
            <b><a href="https://hildekuehne.github.io/">Hilde Kuehne</a></b></br>
            Assistant Professor, Goethe University
        </p>
    </div>
    <div id="member">
        <img src="./profiles/ehsan.png">
        <p>
            <b><a href="https://www.ccs.neu.edu/home/eelhami/">Ehsan Elhamifar</a></b></br>
            Associate Professor, Northeastern University
        </p>
    </div>
    <div id="member">
        <img src="./profiles/yougesh.png">
        <p>
            <b><a href="https://www.crcv.ucf.edu/person/rawat/">Yogesh S Rawat</a></b></br>
            Assistant Professor, University of Central Florida
        </p>
    </div>
</div>
}}

= Schedule

- *Opening Remarks* (9:00 - 9:10am, /Organizers/) 
- *Invited Speaker: Angela Yao* (9:10 - 9:45am) \[[video]\] \[[slide]\]#\[[ Resources]\]|\[[Slides]\]|\[[YouTube]\]|\[[Survey]\]
- *Invited Speaker: Junsong Yuan* (9:45 - 10:20am) \[[video]\] \[[slide]\]
- *Coffee Break* (10:20 - 10:40am) 
- *Invited Speaker: Hilde Kuehne* (10:40 - 11:15am) \[[video]\] \[[slide]\]
- *Invited Speaker: Ehsan Elhamifar* (11:15 - 11:50am) \[[video]\] \[[slide]\]
- *Invited Speaker: Yogesh S Rawat* (11:50 - 12:25pm) \[[video]\] \[[slide]\]
- *Conclusion* (12:25 - 12:30pm, /All/)



= Resources
- *Work Compliation*
. Awesome Temporal Action Segmentation \[[https://github.com/atlas-eccv22/awesome-temporal-action-segmentation Github]\]
. Awesome Temporal Action Localization \[[https://github.com/Alvin-Zeng/Awesome-Temporal-Action-Localization Github]\]
- *Survey*
. Temporal Action Segmentation: An Analysis of Modern Technique, /2022/. Guodong Ding, Fadime Sener and Angela Yao. \[[https://arxiv.org/pdf/2210.10352.pdf PDF]\]
. Weakly-supervised Temporal Action Localization: A Survey, /2022/. AbdulRahman Baraka and Mohd Halim Mohd Noor. \[[https://link.springer.com/article/10.1007/s00521-022-07102-x PDF]\]
. A Survey on Temporal Action Localization, /2020/. Huifen Xia and Yongzhao Zhan \[[https://ieeexplore.ieee.org/document/9062498 PDF]\]
= Organizers
{{
<div id="member-container">
    <div id="member">
        <img src="./profiles/angela.png">
        <p>
            <b>Angela Yao</b></br>
            Assistant Professor, National University of Singapore
        </p>
    </div>
    <div id="member">
        <img src="./profiles/junsong.png">
        <p>
            <b>Junsong Yuan</b></br>
            Professor, SUNY Buffalo
        </p>
    </div>
    <div id="member">
        <img src="./profiles/fadime.png">
        <p>
            <b>Fadime Sener</b></br>
            Research Scientist, Reality Labs, Meta
        </p>
    </div>
    <div id="member">
        <img src="./profiles/guodong.png">
        <p>
            <b>Guodong Ding</b></br>
            Research Fellow, National University of Singapore
        </p>
    </div>
</div>
}}
